{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Avi/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Avi/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/Avi/anaconda/lib/python3.6/site-packages/sklearn/lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/Avi/anaconda/lib/python3.6/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/Avi/anaconda/lib/python3.6/site-packages/sklearn/qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from datetime import datetime\n",
    "\n",
    "data = {\n",
    "    'tra': pd.read_csv('Raw/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('Raw/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('Raw/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('Raw/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('Raw/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('Raw/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('Raw/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('Raw/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "    tmp1 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "    data[df] = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) \n",
    "                    for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.457143</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.920635</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Izakaya</td>\n",
       "      <td>Tōkyō-to Taitō-ku Higashiueno</td>\n",
       "      <td>35.712607</td>\n",
       "      <td>139.779996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_0328696196e46f18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Ōsaka-fu Ōsaka-shi Nakanochō</td>\n",
       "      <td>34.701279</td>\n",
       "      <td>135.528090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_034a3d5b40d5b1b1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.864865</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Cafe/Sweets</td>\n",
       "      <td>Ōsaka-fu Ōsaka-shi Ōhiraki</td>\n",
       "      <td>34.692337</td>\n",
       "      <td>135.472229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  min_visitors  mean_visitors  median_visitors  \\\n",
       "0  air_00a91d42b08b08d9    0           1.0      22.457143             19.0   \n",
       "1  air_0164b9927d20bcc3    0           2.0       7.500000              6.0   \n",
       "2  air_0241aa3964b7f861    0           2.0       8.920635              8.0   \n",
       "3  air_0328696196e46f18    0           2.0       6.416667              4.0   \n",
       "4  air_034a3d5b40d5b1b1    0           1.0      11.864865             10.0   \n",
       "\n",
       "   max_visitors  count_observations  air_genre_name  \\\n",
       "0          47.0                35.0  Italian/French   \n",
       "1          19.0                20.0  Italian/French   \n",
       "2          23.0                63.0         Izakaya   \n",
       "3          27.0                12.0      Dining bar   \n",
       "4          66.0                37.0     Cafe/Sweets   \n",
       "\n",
       "                     air_area_name   latitude   longitude  \n",
       "0  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \n",
       "1     Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599  \n",
       "2    Tōkyō-to Taitō-ku Higashiueno  35.712607  139.779996  \n",
       "3     Ōsaka-fu Ōsaka-shi Nakanochō  34.701279  135.528090  \n",
       "4       Ōsaka-fu Ōsaka-shi Ōhiraki  34.692337  135.472229  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "\n",
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id']) \n",
    "\n",
    "stores.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\n",
    "stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for i in range(10):\n",
    "    stores['air_genre_name'+str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    stores['air_area_name'+str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['air_store_id', 'dow', 'min_visitors', 'mean_visitors',\n",
       "       'median_visitors', 'max_visitors', 'count_observations',\n",
       "       'air_genre_name', 'air_area_name', 'latitude', 'longitude',\n",
       "       'air_genre_name0', 'air_area_name0', 'air_genre_name1',\n",
       "       'air_area_name1', 'air_genre_name2', 'air_area_name2',\n",
       "       'air_genre_name3', 'air_area_name3', 'air_genre_name4',\n",
       "       'air_area_name4', 'air_genre_name5', 'air_area_name5',\n",
       "       'air_genre_name6', 'air_area_name6', 'air_genre_name7',\n",
       "       'air_area_name7', 'air_genre_name8', 'air_area_name8',\n",
       "       'air_genre_name9', 'air_area_name9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors  dow  year  month  day_of_week  \\\n",
       "0  air_ba937bf13d40fb24  2016-01-13        25    2  2016      1            6   \n",
       "1  air_ba937bf13d40fb24  2016-01-14        32    3  2016      1            4   \n",
       "2  air_ba937bf13d40fb24  2016-01-15        29    4  2016      1            0   \n",
       "3  air_ba937bf13d40fb24  2016-01-16        22    5  2016      1            2   \n",
       "4  air_ba937bf13d40fb24  2016-01-18         6    0  2016      1            1   \n",
       "\n",
       "   holiday_flg  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, stores, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(test, stores, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n",
    "\n",
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>rv1_y</th>\n",
       "      <th>rs2_y</th>\n",
       "      <th>rv2_y</th>\n",
       "      <th>id</th>\n",
       "      <th>total_reserv_sum</th>\n",
       "      <th>total_reserv_mean</th>\n",
       "      <th>total_reserv_dt_diff_mean</th>\n",
       "      <th>date_int</th>\n",
       "      <th>var_max_lat</th>\n",
       "      <th>var_max_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.843750</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160113</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.292308</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160114</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.738462</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160115</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.651515</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160116</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.754386</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160118</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors  dow  year  month  day_of_week  \\\n",
       "0  air_ba937bf13d40fb24  2016-01-13        25    2  2016      1            6   \n",
       "1  air_ba937bf13d40fb24  2016-01-14        32    3  2016      1            4   \n",
       "2  air_ba937bf13d40fb24  2016-01-15        29    4  2016      1            0   \n",
       "3  air_ba937bf13d40fb24  2016-01-16        22    5  2016      1            2   \n",
       "4  air_ba937bf13d40fb24  2016-01-18         6    0  2016      1            1   \n",
       "\n",
       "   holiday_flg  min_visitors  mean_visitors      ...       rv1_y  rs2_y  \\\n",
       "0            0           7.0      23.843750      ...         NaN    NaN   \n",
       "1            0           2.0      20.292308      ...         NaN    NaN   \n",
       "2            0           4.0      34.738462      ...         NaN    NaN   \n",
       "3            0           6.0      27.651515      ...         NaN    NaN   \n",
       "4            0           2.0      13.754386      ...         NaN    NaN   \n",
       "\n",
       "   rv2_y                               id  total_reserv_sum  \\\n",
       "0    NaN  air_ba937bf13d40fb24_2016-01-13               NaN   \n",
       "1    NaN  air_ba937bf13d40fb24_2016-01-14               NaN   \n",
       "2    NaN  air_ba937bf13d40fb24_2016-01-15               NaN   \n",
       "3    NaN  air_ba937bf13d40fb24_2016-01-16               NaN   \n",
       "4    NaN  air_ba937bf13d40fb24_2016-01-18               NaN   \n",
       "\n",
       "   total_reserv_mean  total_reserv_dt_diff_mean  date_int  var_max_lat  \\\n",
       "0                NaN                        NaN  20160113     8.362564   \n",
       "1                NaN                        NaN  20160114     8.362564   \n",
       "2                NaN                        NaN  20160115     8.362564   \n",
       "3                NaN                        NaN  20160116     8.362564   \n",
       "4                NaN                        NaN  20160118     8.362564   \n",
       "\n",
       "   var_max_long  \n",
       "0      4.521799  \n",
       "1      4.521799  \n",
       "2      4.521799  \n",
       "3      4.521799  \n",
       "4      4.521799  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test['air_store_id2'] = lbl.transform(test['air_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE GradientBoostingRegressor:  0.502272686555\n",
      "RMSE KNeighborsRegressor:  0.419451716114\n"
     ]
    }
   ],
   "source": [
    "model1 = ensemble.GradientBoostingRegressor(learning_rate=0.2, random_state=3)\n",
    "model2 = neighbors.KNeighborsRegressor(n_jobs=-1, n_neighbors=4)\n",
    "model1.fit(train[col], np.log1p(train['visitors'].values))\n",
    "model2.fit(train[col], np.log1p(train['visitors'].values))\n",
    "print('RMSE GradientBoostingRegressor: ', RMSLE(np.log1p(train['visitors'].values), model1.predict(train[col])))\n",
    "print('RMSE KNeighborsRegressor: ', RMSLE(np.log1p(train['visitors'].values), model2.predict(train[col])))\n",
    "test['visitors'] = (model1.predict(test[col]) + model2.predict(test[col])) / 2\n",
    "test['visitors'] = np.expm1(test['visitors']).clip(lower=0.)\n",
    "sub1 = test[['id','visitors']].copy()\n",
    "del train; del data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = { re.search('/([^/\\.]*)\\.csv', fn).group(1):\n",
    "    pd.read_csv(fn)for fn in glob.glob('Raw/*.csv')}\n",
    "\n",
    "for k, v in dfs.items(): locals()[k] = v\n",
    "\n",
    "wkend_holidays = date_info.apply(\n",
    "    (lambda x:(x.day_of_week=='Sunday' or x.day_of_week=='Saturday') and x.holiday_flg==1), axis=1)\n",
    "date_info.loc[wkend_holidays, 'holiday_flg'] = 0\n",
    "date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5  \n",
    "\n",
    "visit_data = air_visit_data.merge(date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "visit_data.drop('calendar_date', axis=1, inplace=True)\n",
    "visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "wmean = lambda x:( (x.weight * x.visitors).sum() / x.weight.sum() )\n",
    "visitors = visit_data.groupby(['air_store_id', 'day_of_week', 'holiday_flg']).apply(wmean).reset_index()\n",
    "visitors.rename(columns={0:'visitors'}, inplace=True) # cumbersome, should be better ways.\n",
    "\n",
    "sample_submission['air_store_id'] = sample_submission.id.map(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "sample_submission['calendar_date'] = sample_submission.id.map(lambda x: x.split('_')[2])\n",
    "sample_submission.drop('visitors', axis=1, inplace=True)\n",
    "sample_submission = sample_submission.merge(date_info, on='calendar_date', how='left')\n",
    "sample_submission = sample_submission.merge(visitors, on=[\n",
    "    'air_store_id', 'day_of_week', 'holiday_flg'], how='left')\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[visitors.holiday_flg==0], on=('air_store_id', 'day_of_week'), \n",
    "    how='left')['visitors_y'].values\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), \n",
    "    on='air_store_id', how='left')['visitors_y'].values\n",
    "\n",
    "sample_submission['visitors'] = sample_submission.visitors.map(pd.np.expm1)\n",
    "sub2 = sample_submission[['id', 'visitors']].copy()\n",
    "sub_merge = pd.merge(sub1, sub2, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_merge['visitors'] = (sub_merge['visitors_x'] + sub_merge['visitors_y']* 1.1)/2\n",
    "sub_merge[['id', 'visitors']].to_csv('submission50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data frames read:['air_reserve', 'air_store_info', 'air_visit_data', 'date_info', 'hpg_reserve', 'hpg_store_info', 'sample_submission', 'store_id_relation']\n",
      "local variables with the same names are created.\n",
      "Raw shape of each dataset\n",
      "air_reserve :  (92378, 4)\n",
      "air_store_info :  (829, 5)\n",
      "air_visit_data :  (252108, 3)\n",
      "date_info :  (517, 3)\n",
      "hpg_reserve :  (2000320, 4)\n",
      "hpg_store_info :  (4690, 5)\n",
      "sample_submission :  (32019, 2)\n",
      "store_id_relation :  (150, 2)\n",
      "Split id column in sample_submission\n",
      "Unique store Ids in each dataset\n",
      "air_reserve  - Unqiue air_stores:  314\n",
      "air_store_info  - Unqiue air_stores:  829\n",
      "air_visit_data  - Unqiue air_stores:  829\n",
      "hpg_reserve  - Unqiue hpg_stores:  13325\n",
      "hpg_store_info  - Unqiue hpg_stores:  4690\n",
      "sample_submission  - Unqiue air_stores:  821\n",
      "store_id_relation  - Unqiue air_stores:  150\n",
      "store_id_relation  - Unqiue hpg_stores:  150\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import os,glob, re\n",
    "get_ipython().magic('matplotlib inline')\n",
    "\n",
    "dfs = {re.search('([a-zA-Z_]*)\\.csv', fn).group(1):pd.read_csv(fn) for fn in glob.glob(os.getcwd()+'//Raw//*.csv')}\n",
    "print('data frames read:{}'.format(list(dfs.keys())))\n",
    "\n",
    "print('local variables with the same names are created.')\n",
    "for k, v in dfs.items(): locals()[k] = v\n",
    "\n",
    "\n",
    "print(\"Raw shape of each dataset\")\n",
    "for k, v in dfs.items(): print(\"%s : \"%k,v.shape)\n",
    "\n",
    "print(\"Split id column in sample_submission\")\n",
    "sample_submission[\"air_store_id\"],sample_submission[\"visit_date\"] = sample_submission.id.str[:20],sample_submission.id.str[21:]\n",
    "sample_submission.head()\n",
    "\n",
    "print(\"Unique store Ids in each dataset\")\n",
    "for k, v in dfs.items(): \n",
    "    try:       \n",
    "        print(k,\" - Unqiue air_stores: \",v.air_store_id.nunique())\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print(k,\" - Unqiue hpg_stores: \",v.hpg_store_id.nunique())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "air_reserve['visit_date'] = pd.to_datetime(air_reserve['visit_datetime']).dt.date.astype(str)\n",
    "\n",
    "reserve_summary = air_reserve.groupby(['air_store_id','visit_date'])['reserve_visitors'].sum().reset_index()\n",
    "\n",
    "new_train = air_visit_data.merge(reserve_summary, on =['air_store_id','visit_date'],how = 'left').fillna(0)\n",
    "\n",
    "new_train['walkins'] = new_train['visitors'] - new_train['reserve_visitors']\n",
    "new_train.loc[new_train['walkins'] <0,'walkins'] = 0\n",
    "new_train['noshows'] = new_train['reserve_visitors'] - new_train['visitors']\n",
    "new_train.loc[new_train['noshows'] <0,'noshows'] = 0\n",
    "new_train.head()\n",
    "\n",
    "weekdayholidays = date_info.apply(lambda x: x.day_of_week in ['Saturday','Sunday'] and x.holiday_flg == 1,axis=1)\n",
    "date_info.loc[weekdayholidays,'holiday_flg'] = 0\n",
    "\n",
    "date_info['weights'] = ((date_info.index + 1)/ len(date_info))**7\n",
    "\n",
    "new_train = new_train.merge(date_info,left_on = 'visit_date',right_on = 'calendar_date', how ='left').drop('calendar_date',axis = 1)\n",
    "\n",
    "new_train['visitors'] = new_train['visitors'].apply(pd.np.log1p)\n",
    "new_train['reserve_visitors'] = new_train['reserve_visitors'].apply(pd.np.log1p)\n",
    "new_train['walkins'] = new_train['walkins'].apply(pd.np.log1p)\n",
    "new_train['noshows'] = new_train['noshows'].apply(pd.np.log1p)\n",
    "\n",
    "weighted_mean_visitors = lambda x : ((x.visitors * x.weights).sum() / (x.weights).sum())\n",
    "visitors_per_weekday = new_train.groupby(['air_store_id','day_of_week','holiday_flg']).apply(weighted_mean_visitors).reset_index()\n",
    "\n",
    "weighted_mean_reservations = lambda x : ((x.reserve_visitors * x.weights).sum() / (x.weights).sum())\n",
    "reserves_per_weekday = new_train.groupby(['air_store_id','day_of_week','holiday_flg']).apply(weighted_mean_reservations).reset_index()\n",
    "reserves_per_weekday.head()\n",
    "\n",
    "weighted_mean_walkins = lambda x : ((x.walkins * x.weights).sum() / (x.weights).sum())\n",
    "walkin_visitors_per_weekday = new_train.groupby(['air_store_id','day_of_week','holiday_flg']).apply(weighted_mean_walkins).reset_index()\n",
    "\n",
    "weighted_mean_noshows = lambda x : ((x.noshows * x.weights).sum() / (x.weights).sum())\n",
    "noshows_per_weekday = new_train.groupby(['air_store_id','day_of_week','holiday_flg']).apply(weighted_mean_noshows).reset_index()\n",
    "\n",
    "summarized_train = visitors_per_weekday.merge(\n",
    "    reserves_per_weekday, on= ['air_store_id','day_of_week','holiday_flg'],how = 'outer')\n",
    "\n",
    "summarized_train.rename(columns={'0_x':'wt_visitors','0_y':'wt_reserves'},inplace = True)\n",
    "\n",
    "summarized_train = summarized_train.merge(\n",
    "    walkin_visitors_per_weekday, on = ['air_store_id','day_of_week','holiday_flg'],how ='outer')\n",
    "\n",
    "summarized_train = summarized_train.merge(\n",
    "    noshows_per_weekday, on= ['air_store_id','day_of_week','holiday_flg'],how = 'outer')\n",
    "\n",
    "summarized_train.rename(columns={'0_x':'walkins','0_y':'noshows'},inplace = True)\n",
    "\n",
    "\n",
    "test = sample_submission.merge(date_info,left_on='visit_date',right_on='calendar_date',how = 'left').drop(['calendar_date','weights'],axis = 1)\n",
    "\n",
    "newtest = test.merge(reserve_summary, on=['air_store_id','visit_date'], how='left').fillna(0)\n",
    "\n",
    "newtest = newtest.merge(summarized_train,on = ['air_store_id','day_of_week','holiday_flg'], how = 'left')\n",
    "\n",
    "temp = newtest[newtest.wt_visitors.isnull()].merge(summarized_train[summarized_train.holiday_flg == 0]\n",
    "                                            ,on = ['air_store_id','day_of_week'], how = 'left')\n",
    "\n",
    "\n",
    "newtest.loc[newtest.wt_visitors.isnull(),'wt_visitors'] = temp['wt_visitors_y'].values\n",
    "newtest.loc[newtest.wt_reserves.isnull(),'wt_reserves'] = temp['wt_reserves_y'].values\n",
    "newtest.loc[newtest.walkins.isnull(),'walkins'] = temp['walkins_y'].values\n",
    "newtest.loc[newtest.noshows.isnull(),'noshows'] = temp['noshows_y'].values\n",
    "\n",
    "\n",
    "temp2 = newtest[newtest.wt_visitors.isnull()].merge(summarized_train[[\n",
    "    'air_store_id','wt_visitors','wt_reserves','walkins','noshows']].groupby('air_store_id').mean().reset_index(),\n",
    "                                                    on = 'air_store_id',how = \"left\")\n",
    "\n",
    "newtest.loc[newtest.wt_visitors.isnull(),'wt_visitors'] = temp2['wt_visitors_y'].values\n",
    "newtest.loc[newtest.wt_reserves.isnull(),'wt_reserves'] = temp2['wt_reserves_y'].values\n",
    "newtest.loc[newtest.walkins.isnull(),'walkins'] = temp2['walkins_y'].values\n",
    "newtest.loc[newtest.noshows.isnull(),'noshows'] = temp2['noshows_y'].values\n",
    "\n",
    "\n",
    "max_visitors = air_visit_data.groupby('air_store_id')['visitors'].max().reset_index()\n",
    "max_visitors.rename(columns = {'visitors' : 'max_cap'},inplace = True)\n",
    "\n",
    "newtest = newtest.merge(max_visitors,on= 'air_store_id', how = 'left')\n",
    "\n",
    "newtest.drop(['visitors','air_store_id','visit_date','day_of_week','holiday_flg'],inplace = True,axis = 1)\n",
    "\n",
    "newtest['wt_visitors'] = newtest['wt_visitors'].apply(pd.np.expm1)\n",
    "newtest['wt_reserves'] = newtest['wt_reserves'].apply(pd.np.expm1)\n",
    "newtest['walkins'] = newtest['walkins'].apply(pd.np.expm1)\n",
    "newtest['noshows'] = newtest['noshows'].apply(pd.np.expm1)\n",
    "\n",
    "newtest['calculated_visits'] = ((newtest['reserve_visitors']+newtest['wt_reserves'])/2) +newtest['walkins'] - newtest['noshows']\n",
    "\n",
    "newtest['visitors'] = newtest['calculated_visits']\n",
    "\n",
    "# k = .6\n",
    "\n",
    "# newtest['visitors'] = ((newtest['wt_visitors'] * k) + ((1-k)*newtest['calculated_visits']))\n",
    "\n",
    "\n",
    "# newtest.loc[newtest['visitors'] > newtest['max_cap'],'visitors'] = newtest['max_cap']\n",
    "\n",
    "\n",
    "# newtest.loc[newtest['visitors'] < 0,'visitors'] = newtest['wt_reserves']\n",
    "\n",
    "\n",
    "result = newtest[['id','visitors']]\n",
    "\n",
    "\n",
    "#result.to_csv('result_dump4.csv', float_format='%.4f', index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>24.137141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>27.399424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>27.299089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>31.507420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id   visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23   2.000000\n",
       "1  air_00a91d42b08b08d9_2017-04-24  24.137141\n",
       "2  air_00a91d42b08b08d9_2017-04-25  27.399424\n",
       "3  air_00a91d42b08b08d9_2017-04-26  27.299089\n",
       "4  air_00a91d42b08b08d9_2017-04-27  31.507420"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors_x</th>\n",
       "      <th>visitors_y</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>2.555948</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.377974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>20.944645</td>\n",
       "      <td>23.621632</td>\n",
       "      <td>23.464220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>25.206066</td>\n",
       "      <td>26.823130</td>\n",
       "      <td>27.355755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>27.570890</td>\n",
       "      <td>27.600920</td>\n",
       "      <td>28.965951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>31.519827</td>\n",
       "      <td>31.299646</td>\n",
       "      <td>32.974719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors_x  visitors_y   visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23    2.555948    2.000000   2.377974\n",
       "1  air_00a91d42b08b08d9_2017-04-24   20.944645   23.621632  23.464220\n",
       "2  air_00a91d42b08b08d9_2017-04-25   25.206066   26.823130  27.355755\n",
       "3  air_00a91d42b08b08d9_2017-04-26   27.570890   27.600920  28.965951\n",
       "4  air_00a91d42b08b08d9_2017-04-27   31.519827   31.299646  32.974719"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsub = sub_merge[['id','visitors']].merge(result,how = 'inner',on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors_x</th>\n",
       "      <th>visitors_y</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>2.377974</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.777974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>23.464220</td>\n",
       "      <td>24.137141</td>\n",
       "      <td>28.188547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>27.355755</td>\n",
       "      <td>27.399424</td>\n",
       "      <td>32.720381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>28.965951</td>\n",
       "      <td>27.299089</td>\n",
       "      <td>34.486135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>32.974719</td>\n",
       "      <td>31.507420</td>\n",
       "      <td>39.234648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors_x  visitors_y   visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23    2.377974    2.000000   2.777974\n",
       "1  air_00a91d42b08b08d9_2017-04-24   23.464220   24.137141  28.188547\n",
       "2  air_00a91d42b08b08d9_2017-04-25   27.355755   27.399424  32.720381\n",
       "3  air_00a91d42b08b08d9_2017-04-26   28.965951   27.299089  34.486135\n",
       "4  air_00a91d42b08b08d9_2017-04-27   32.974719   31.507420  39.234648"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsub['visitors'] = (newsub['visitors_x'] + newsub['visitors_y'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitors_x</th>\n",
       "      <th>visitors_y</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32019.000000</td>\n",
       "      <td>32019.000000</td>\n",
       "      <td>32019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.247140</td>\n",
       "      <td>17.466975</td>\n",
       "      <td>20.103755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.801313</td>\n",
       "      <td>13.695208</td>\n",
       "      <td>14.943723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.149288</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>0.402735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.014777</td>\n",
       "      <td>7.416091</td>\n",
       "      <td>9.014223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.712170</td>\n",
       "      <td>13.781842</td>\n",
       "      <td>16.196971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.018804</td>\n",
       "      <td>23.869239</td>\n",
       "      <td>27.287538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>143.001379</td>\n",
       "      <td>280.390355</td>\n",
       "      <td>182.310238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         visitors_x    visitors_y      visitors\n",
       "count  32019.000000  32019.000000  32019.000000\n",
       "mean      19.247140     17.466975     20.103755\n",
       "std       13.801313     13.695208     14.943723\n",
       "min        1.149288     -7.500000      0.402735\n",
       "25%        9.014777      7.416091      9.014223\n",
       "50%       15.712170     13.781842     16.196971\n",
       "75%       26.018804     23.869239     27.287538\n",
       "max      143.001379    280.390355    182.310238"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsub[['id', 'visitors']].to_csv('submission52.csv', index=False)\n",
    "\n",
    "# rank - 0.485"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
