{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data frames read:['air_reserve', 'air_store_info', 'air_visit_data', 'date_info', 'hpg_reserve', 'hpg_store_info', 'sample_submission', 'store_id_relation']\n",
      "local variables with the same names are created.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import os,glob, re\n",
    "%matplotlib inline\n",
    "\n",
    "dfs = {re.search('([a-zA-Z_]*)\\.csv', fn).group(1):pd.read_csv(fn) for fn in glob.glob(os.getcwd()+'//Raw//*.csv')}\n",
    "print('data frames read:{}'.format(list(dfs.keys())))\n",
    "\n",
    "print('local variables with the same names are created.')\n",
    "for k, v in dfs.items(): locals()[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data ...\n",
      "Loading Data Compelete.\n",
      "=========================================================================================\n",
      "Data Exploring ...\n",
      "=========================================================================================\n",
      "Unique store id in different dataset :\n",
      "-----------------------------------------------------------------------------------------\n",
      "Number of unique stores in 'df_ar' is:314\n",
      "Number of unique stores in 'df_as' is:829\n",
      "Number of unique stores in 'df_av' is:829\n",
      "-----------------------------------------------------------------------------------------\n",
      "Number of unique stores in 'df_hr' is:13325\n",
      "Number of unique stores in 'df_hs' is:4690\n",
      "-----------------------------------------------------------------------------------------\n",
      "Number of unique stores in 'df_test' is:821\n",
      "-----------------------------------------------------------------------------------------\n",
      "Number of unique stores in 'df_test' is:150\n",
      "=========================================================================================\n",
      "mapping and dropping useless information in df_hr ...\n",
      "mapping and dropping useless information in df_hr Done!\n",
      "-----------------------------------------------------------------------------------------\n",
      "mapping and dropping useless information in df_hr ...\n",
      "mapping and dropping useless information in df_hs Done!\n",
      "=========================================================================================\n",
      "seperating date time features ...\n",
      "seperating date time features done! ...\n",
      "=========================================================================================\n",
      "label encoding ...\n",
      "label encoding done !\n",
      "=========================================================================================\n",
      "merging dataframes ...\n",
      "merging dataframes done!\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov 29 10:49:08 2017\n",
    "\n",
    "@author: Mengfei Li\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "from ml_metrics import rmsle\n",
    "\n",
    "print(\"Loading Data ...\")\n",
    "# air_reserve\n",
    "df_ar = air_reserve.copy()#pd.read_csv('../input/air_reserve.csv')\n",
    "# air_store_info\n",
    "df_as = air_store_info.copy()#pd.read_csv('../input/air_store_info.csv')\n",
    "# air_visit_data\n",
    "df_av = air_visit_data.copy()#pd.read_csv('../input/air_visit_data.csv')\n",
    "# hpg_reserve\n",
    "df_hr = hpg_reserve.copy()#pd.read_csv('../input/hpg_reserve.csv')\n",
    "# hpg_store_info\n",
    "df_hs = hpg_store_info.copy()#pd.read_csv('../input/hpg_store_info.csv')\n",
    "# date_info\n",
    "df_di = date_info.copy()#pd.read_csv('../input/date_info.csv')\n",
    "# sample_submission\n",
    "df_ss = sample_submission.copy()#pd.read_csv('../input/sample_submission.csv')\n",
    "# store_id_relation\n",
    "df_si = store_id_relation.copy()#pd.read_csv('../input/store_id_relation.csv')\n",
    "\n",
    "# df_test\n",
    "df_test = sample_submission.copy()#pd.read_csv('../input/sample_submission.csv')\n",
    "df_test['air_store_id'] = df_test['id'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
    "df_test['visit_date'] = df_test['id'].apply(lambda x: x.split('_')[-1])\n",
    "index_test = df_test['id']\n",
    "del df_test['id'], df_test['visitors']\n",
    "\n",
    "gc.collect()\n",
    "print(\"Loading Data Compelete.\")\n",
    "\n",
    "print(\"=========================================================================================\")\n",
    "print(\"Data Exploring ...\")\n",
    "print(\"=========================================================================================\")\n",
    "print(\"Unique store id in different dataset :\")\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "num_store_ar = np.unique(df_ar['air_store_id'])\n",
    "print(\"Number of unique stores in 'df_ar' is:\" + str(len(num_store_ar)))\n",
    "\n",
    "num_store_as = np.unique(df_as['air_store_id'])\n",
    "print(\"Number of unique stores in 'df_as' is:\" + str(len(num_store_as)))\n",
    "\n",
    "num_store_av = np.unique(df_av['air_store_id'])\n",
    "print(\"Number of unique stores in 'df_av' is:\" + str(len(num_store_av)))\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "num_store_in_hr = np.unique(df_hr['hpg_store_id'])\n",
    "print(\"Number of unique stores in 'df_hr' is:\" + str(len(num_store_in_hr)))\n",
    "\n",
    "num_store_in_hs = np.unique(df_hs['hpg_store_id'])\n",
    "print(\"Number of unique stores in 'df_hs' is:\" + str(len(num_store_in_hs)))\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "num_store_in_test = np.unique(df_test['air_store_id'])\n",
    "print(\"Number of unique stores in 'df_test' is:\" + str(len(num_store_in_test)))\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "num_store_in_si = np.unique(df_si['air_store_id'])\n",
    "print(\"Number of unique stores in 'df_test' is:\" + str(len(num_store_in_si)))\n",
    "print(\"=========================================================================================\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# remove outliers\n",
    "# =============================================================================\n",
    "def remove_outliers(data):\n",
    "    df_0 = data.loc[data.visitors == 0]   \n",
    "    q1 = np.percentile(data.visitors, 25, axis=0)\n",
    "    q3 = np.percentile(data.visitors, 75, axis=0)\n",
    "#    k = 5\n",
    "#    k = 2.5\n",
    "    k = 2.8\n",
    "#    k = 2\n",
    "#    k = 1.5\n",
    "    iqr = q3 - q1\n",
    "    df_temp = data.loc[data.visitors > q1 - k*iqr]\n",
    "    df_temp = data.loc[data.visitors < q3 + k*iqr]\n",
    "    frames = [df_0, df_temp]\n",
    "    result = pd.concat(frames)\n",
    "    return result\n",
    "\n",
    "df_av = remove_outliers(df_av)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# df to dict for mapping and dropping\n",
    "# =============================================================================\n",
    "print('mapping and dropping useless information in df_hr ...')\n",
    "s_1 = df_si['air_store_id']\n",
    "s_2 = df_si['hpg_store_id']\n",
    "a_h_map = dict(zip(s_2.values, s_1.values))\n",
    "del s_1, s_2\n",
    "\n",
    "df_hr['air_store_id'] = df_hr['hpg_store_id'].map(a_h_map)\n",
    "df_hr = df_hr.drop('hpg_store_id', axis=1).dropna()\n",
    "\n",
    "\n",
    "print('mapping and dropping useless information in df_hr Done!')\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "\n",
    "print('mapping and dropping useless information in df_hr ...')\n",
    "\n",
    "df_hs['air_store_id'] = df_hs['hpg_store_id'].map(a_h_map)\n",
    "df_hs = df_hs.drop('hpg_store_id', axis=1).dropna()\n",
    "print('mapping and dropping useless information in df_hs Done!')\n",
    "gc.collect()\n",
    "print(\"=========================================================================================\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# handle datetime (no clock info)\n",
    "# =============================================================================\n",
    "print('seperating date time features ...')\n",
    "\n",
    "time_format = '%Y-%m-%d'\n",
    "def seperate_date(data):     \n",
    "    # split date feature in real visit datetime\n",
    "    data_time = pd.to_datetime(data.visit_date, format=time_format)\n",
    "    data['Year_visit']= data_time.dt.year\n",
    "    data['Month_visit'] = data_time.dt.month\n",
    "    data['DayOfYear_visit'] = data_time.dt.dayofyear\n",
    "    # data['DayOfMonth_visit'] = data_time.dt.day\n",
    "#    data['WeekOfYear_visit'] = data_time.dt.week\n",
    "    data['DayOfWeek_visit'] = data_time.dt.dayofweek\n",
    "#    del data['visit_date']\n",
    "    return data\n",
    "\n",
    "seperate_date(df_av)\n",
    "seperate_date(df_test)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "def seperate_date(data):\n",
    "    # split date feature in reservation datetime\n",
    "    data_time = pd.to_datetime(data.reserve_datetime, format=time_format)\n",
    "    data['Year_re']= data_time.dt.year\n",
    "    data['Month_re'] = data_time.dt.month\n",
    "    data['DayOfYear_re'] = data_time.dt.dayofyear\n",
    "    # data['DayOfMonth_re'] = data_time.dt.day\n",
    "#    data['WeekOfYear_re'] = data_time.dt.week\n",
    "    data['DayOfWeek_re'] = data_time.dt.dayofweek\n",
    "    data['Hour_re'] = data_time.dt.hour\n",
    "#    del data['reserve_datetime']\n",
    "    return data\n",
    "\n",
    "seperate_date(df_ar)\n",
    "\n",
    "\n",
    "def seperate_date(data):\n",
    "    # split date feature in reservation datetime\n",
    "    data_time = pd.to_datetime(data.reserve_datetime, format=time_format)\n",
    "    data['Year_re_h']= data_time.dt.year\n",
    "    data['Month_re_h'] = data_time.dt.month\n",
    "    data['DayOfYear_re_h'] = data_time.dt.dayofyear\n",
    "    # data['DayOfMonth_re_h'] = data_time.dt.day\n",
    "#    data['WeekOfYear_re_h'] = data_time.dt.week\n",
    "    data['DayOfWeek_re_h'] = data_time.dt.dayofweek\n",
    "    data['Hour_re_h'] = data_time.dt.hour\n",
    "#    del data['reserve_datetime']\n",
    "    return data\n",
    "\n",
    "seperate_date(df_hr)\n",
    "\n",
    "\n",
    "time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "def seperate_date(data):\n",
    "    # split date feature in reserved visiting datetime\n",
    "    data_time = pd.to_datetime(data.visit_datetime, format=time_format)\n",
    "    data['Year_re_visit']= data_time.dt.year\n",
    "    data['Month_re_visit'] = data_time.dt.month\n",
    "    data['DayOfYear_re_visit'] = data_time.dt.dayofyear\n",
    "    # data['DayOfMonth_re_visit'] = data_time.dt.day\n",
    "#    data['WeekOfYear_re_visit'] = data_time.dt.week\n",
    "    data['DayOfWeek_re_visit'] = data_time.dt.dayofweek\n",
    "    data['Hour_re_visit'] = data_time.dt.hour\n",
    "#    del data['visit_datetime']\n",
    "    return data\n",
    "\n",
    "seperate_date(df_ar)\n",
    "\n",
    "\n",
    "def seperate_date(data):\n",
    "    # split date feature in reserved visiting datetime\n",
    "    data_time = pd.to_datetime(data.visit_datetime, format=time_format)\n",
    "    data['Year_re_visit_h']= data_time.dt.year\n",
    "    data['Month_re_visit_h'] = data_time.dt.month\n",
    "    data['DayOfYear_re_visit_h'] = data_time.dt.dayofyear\n",
    "    # data['DayOfMonth_re_visit_h'] = data_time.dt.day\n",
    "    data['WeekOfYear_re_visit_h'] = data_time.dt.week\n",
    "    data['DayOfWeek_re_visit_h'] = data_time.dt.dayofweek\n",
    "    data['Hour_re_visit_h'] = data_time.dt.hour\n",
    "#    del data['visit_datetime']\n",
    "    return data\n",
    "\n",
    "seperate_date(df_hr)\n",
    "\n",
    "print('seperating date time features done! ...')\n",
    "gc.collect()\n",
    "print(\"=========================================================================================\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# label encoding\n",
    "# =============================================================================\n",
    "print('label encoding ...')\n",
    "\n",
    "le.fit(df_as['air_genre_name'])\n",
    "df_as['air_genre_name'] = le.fit_transform(df_as['air_genre_name'])\n",
    "\n",
    "le.fit(df_as['air_area_name'])\n",
    "df_as['air_area_name'] = le.fit_transform(df_as['air_area_name'])\n",
    "\n",
    "le.fit(df_hs['hpg_genre_name'])\n",
    "df_hs['hpg_genre_name'] = le.fit_transform(df_hs['hpg_genre_name'])\n",
    "\n",
    "le.fit(df_hs['hpg_area_name'])\n",
    "df_hs['hpg_area_name'] = le.fit_transform(df_hs['hpg_area_name'])\n",
    "\n",
    "\n",
    "\n",
    "le.fit(df_as['air_store_id'])\n",
    "\n",
    "\n",
    "df_ar['air_store_id'] = le.transform(df_ar['air_store_id'])\n",
    "df_as['air_store_id'] = le.transform(df_as['air_store_id'])\n",
    "df_av['air_store_id'] = le.transform(df_av['air_store_id'])\n",
    "df_hr['air_store_id'] = le.transform(df_hr['air_store_id'])\n",
    "df_hs['air_store_id'] = le.transform(df_hs['air_store_id'])\n",
    "\n",
    "df_test['air_store_id'] = le.transform(df_test['air_store_id'])\n",
    "\n",
    "\n",
    "print('label encoding done !')\n",
    "gc.collect()\n",
    "print(\"=========================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Merge dataset\n",
    "# =============================================================================\n",
    "features_to_drop = [\n",
    "        'air_store_id__'\n",
    "        ]\n",
    "\n",
    "def merge_df(data, data_to_join):\n",
    "    # merge dataframes        \n",
    "    data = data.join(data_to_join, on='air_store_id', rsuffix='__', how='left')   \n",
    "    return data\n",
    "\n",
    "def fix_data(data):\n",
    "    # drop __ data    \n",
    "    for feature in features_to_drop:\n",
    "        del data[feature]\n",
    "    return data\n",
    "\n",
    "# Merge to df_train\n",
    "print('merging dataframes ...')\n",
    "df_train = merge_df(df_av, df_ar)\n",
    "df_train = merge_df(df_train, df_as)\n",
    "\n",
    "df_hr['reserve_visitors_hr'] = df_hr['reserve_visitors'] \n",
    "del df_hr['reserve_visitors'] \n",
    "\n",
    "df_hs['latitude_hr'] = df_hs['latitude'] \n",
    "del df_hs['latitude'] \n",
    "\n",
    "df_hs['longitude_hr'] = df_hs['longitude'] \n",
    "del df_hs['longitude'] \n",
    "\n",
    "df_train = merge_df(df_train, df_hs)\n",
    "df_train = merge_df(df_train, df_hr)\n",
    "gc.collect()\n",
    "fix_data(df_train)\n",
    "\n",
    "# Merge to df_test\n",
    "\n",
    "df_test = merge_df(df_test, df_ar)\n",
    "df_test = merge_df(df_test, df_as)\n",
    "\n",
    "df_test = merge_df(df_test, df_hs)\n",
    "df_test = merge_df(df_test, df_hr)\n",
    "gc.collect()\n",
    "fix_data(df_test)\n",
    "\n",
    "\n",
    "print('merging dataframes done!')\n",
    "gc.collect()\n",
    "print(\"=========================================================================================\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# add holiday feature (for the visiting day)\n",
    "# =============================================================================\n",
    "df_di['visit_date'] = df_di['calendar_date']\n",
    "del df_di['calendar_date'] \n",
    "\n",
    "def add_is_holiday(data):\n",
    "    # merge dataframes        \n",
    "    data = data.merge(df_di, on='visit_date', how='left')\n",
    "    del data['day_of_week']\n",
    "    return data\n",
    "\n",
    "df_train = add_is_holiday(df_train)\n",
    "df_test = add_is_holiday(df_test)\n",
    "\n",
    "# =============================================================================\n",
    "# drop date-time-hour info\n",
    "# =============================================================================\n",
    "def drop_datetime_info(data):\n",
    "    del data['visit_date'], data['visit_datetime'], data['reserve_datetime'], data['visit_datetime__'], data['reserve_datetime__']\n",
    "#    del data['visit_date'], data['visit_datetime'], data['reserve_datetime']\n",
    "    return data\n",
    "df_train = drop_datetime_info(df_train)\n",
    "\n",
    "def drop_datetime_info(data):\n",
    "    del data['visit_date'], data['visit_datetime'], data['reserve_datetime'], data['visit_datetime__'], data['reserve_datetime__']\n",
    "#    del data['visit_date'], data['visit_datetime'], data['reserve_datetime']\n",
    "    return data\n",
    "df_test = drop_datetime_info(df_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['air_store_id', 'visitors', 'Year_visit', 'Month_visit',\n",
       "       'DayOfYear_visit', 'DayOfWeek_visit', 'reserve_visitors', 'Year_re',\n",
       "       'Month_re', 'DayOfYear_re', 'DayOfWeek_re', 'Hour_re', 'Year_re_visit',\n",
       "       'Month_re_visit', 'DayOfYear_re_visit', 'DayOfWeek_re_visit',\n",
       "       'Hour_re_visit', 'air_genre_name', 'air_area_name', 'latitude',\n",
       "       'longitude', 'hpg_genre_name', 'hpg_area_name', 'latitude_hr',\n",
       "       'longitude_hr', 'Year_re_h', 'Month_re_h', 'DayOfYear_re_h',\n",
       "       'DayOfWeek_re_h', 'Hour_re_h', 'Year_re_visit_h', 'Month_re_visit_h',\n",
       "       'DayOfYear_re_visit_h', 'WeekOfYear_re_visit_h', 'DayOfWeek_re_visit_h',\n",
       "       'Hour_re_visit_h', 'reserve_visitors_hr', 'holiday_flg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>Year_visit</th>\n",
       "      <th>Month_visit</th>\n",
       "      <th>DayOfYear_visit</th>\n",
       "      <th>DayOfWeek_visit</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>Year_re</th>\n",
       "      <th>Month_re</th>\n",
       "      <th>DayOfYear_re</th>\n",
       "      <th>...</th>\n",
       "      <th>DayOfWeek_re_h</th>\n",
       "      <th>Hour_re_h</th>\n",
       "      <th>Year_re_visit_h</th>\n",
       "      <th>Month_re_visit_h</th>\n",
       "      <th>DayOfYear_re_visit_h</th>\n",
       "      <th>WeekOfYear_re_visit_h</th>\n",
       "      <th>DayOfWeek_re_visit_h</th>\n",
       "      <th>Hour_re_visit_h</th>\n",
       "      <th>reserve_visitors_hr</th>\n",
       "      <th>holiday_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603</td>\n",
       "      <td>25</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>603</td>\n",
       "      <td>32</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>603</td>\n",
       "      <td>29</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603</td>\n",
       "      <td>22</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>603</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_store_id  visitors  Year_visit  Month_visit  DayOfYear_visit  \\\n",
       "0           603        25        2016            1               13   \n",
       "1           603        32        2016            1               14   \n",
       "2           603        29        2016            1               15   \n",
       "3           603        22        2016            1               16   \n",
       "4           603         6        2016            1               18   \n",
       "\n",
       "   DayOfWeek_visit  reserve_visitors  Year_re  Month_re  DayOfYear_re  \\\n",
       "0                2                 2     2016         1             6   \n",
       "1                3                 2     2016         1             6   \n",
       "2                4                 2     2016         1             6   \n",
       "3                5                 2     2016         1             6   \n",
       "4                0                 2     2016         1             6   \n",
       "\n",
       "      ...       DayOfWeek_re_h  Hour_re_h  Year_re_visit_h  Month_re_visit_h  \\\n",
       "0     ...                  NaN        NaN              NaN               NaN   \n",
       "1     ...                  NaN        NaN              NaN               NaN   \n",
       "2     ...                  NaN        NaN              NaN               NaN   \n",
       "3     ...                  NaN        NaN              NaN               NaN   \n",
       "4     ...                  NaN        NaN              NaN               NaN   \n",
       "\n",
       "   DayOfYear_re_visit_h  WeekOfYear_re_visit_h  DayOfWeek_re_visit_h  \\\n",
       "0                   NaN                    NaN                   NaN   \n",
       "1                   NaN                    NaN                   NaN   \n",
       "2                   NaN                    NaN                   NaN   \n",
       "3                   NaN                    NaN                   NaN   \n",
       "4                   NaN                    NaN                   NaN   \n",
       "\n",
       "   Hour_re_visit_h  reserve_visitors_hr  holiday_flg  \n",
       "0              NaN                  NaN            0  \n",
       "1              NaN                  NaN            0  \n",
       "2              NaN                  NaN            0  \n",
       "3              NaN                  NaN            0  \n",
       "4              NaN                  NaN            0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# autoclean\n",
    "# =============================================================================\n",
    "#df_train_clean = autoclean(df_train)\n",
    "#df_test_clean = autoclean(df_test)\n",
    "#\n",
    "train = df_train.fillna(-1)\n",
    "test = df_test.fillna(-1)\n",
    "#\n",
    "# =============================================================================\n",
    "# shuffle dataset\n",
    "# =============================================================================\n",
    "from sklearn.utils import shuffle\n",
    "train =  shuffle(train, random_state=21)\n",
    "\n",
    "\n",
    "X_train, X_valid = train_test_split(train, test_size=0.05, random_state=42, shuffle=False)\n",
    "\n",
    "X = X_train.drop(['visitors'], axis=1)\n",
    "y = np.log1p(X_train['visitors'].values)\n",
    "d_train = lgb.Dataset(X, y)\n",
    "\n",
    "X = X_valid.drop(['visitors'], axis=1)\n",
    "y = np.log1p(X_valid['visitors'].values)\n",
    "d_valid = lgb.Dataset(X, y)\n",
    "\n",
    "watchlist = [d_train, d_valid]\n",
    "\n",
    "print('Training LGBM model...')\n",
    "params = {}\n",
    "params['application'] = 'regression'\n",
    "params['boosting'] = 'gbdt'\n",
    "params['learning_rate'] = 0.01\n",
    "params['num_leaves'] = 32\n",
    "params['min_sum_hessian_in_leaf'] = 1e-2\n",
    "params['min_gain_to_split'] = 0\n",
    "\n",
    "params['bagging_fraction'] = 0.8\n",
    "params['feature_fraction'] = 0.8\n",
    "params['num_threads'] = 4\n",
    "params['metric'] = 'rmse'\n",
    "\n",
    "lgb_model1 = lgb.train(params, train_set=d_train, num_boost_round=50000, valid_sets=watchlist, \\\n",
    "verbose_eval=10)\n",
    "\n",
    "test_probs = lgb_model1.predict(test)\n",
    "test_probs = np.expm1(test_probs)\n",
    "\n",
    "result = pd.DataFrame({\"id\": index_test, \"visitors\": test_probs})\n",
    "    \n",
    "result.to_csv('LGB_sub.csv', index=False)\n",
    "    \n",
    "    # gbm.save_model(r\"..\\output\\models\\LGB_\"+str(file_name)+'.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
